{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook demonstrates how to synthetically generate mixed audio files at different volumen levels.  The output files generated are used as example mixed audio signal input to deconvolute using Independent Component Analysis (ICA).  The output simulates recording from two observers in a room where a piano is playing Saint-SaÃ«ns \"The Carnival of the Animals - XIII\" and a cello playing Bach's \"Cello Suite no. 3 in C major\".  In one recording, the cello is louder, but the piano can be heard in the background.  And vice versa for the other recording."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input\n",
    "\n",
    "## Download input files\n",
    "\n",
    "Download the following open source recordings.\n",
    "\n",
    "- [The Carnival of the Animals - XIII. The Swan (Solo piano version)](https://musopen.org/music/1454-the-carnival-of-the-animals/#recordings)\n",
    "- [Cello Suite no. 3 in C, BWV 1009 - 3. Courante](https://musopen.org/music/4001-cello-suite-no-3-in-c-major-bwv-1009/#recordings)\n",
    "\n",
    "## Convert to WAV files\n",
    "\n",
    "These files can likely be converted on command line using `ffmpeg`, but I converted them using VLC for this example.  I have included some screenshots of the main steps.\n",
    "\n",
    "1. File --> Convert / Save.  Add file(s) to convert\n",
    "\n",
    "<img src=\"resources/vlc-open-media.png\" width=\"600\"/>\n",
    "\n",
    "2. Create a new profile called \"wav\" with the settings shown below\n",
    "\n",
    "\n",
    "<img src=\"resources/vlc-convert.png\" width=\"600\"/>\n",
    "<img src=\"resources/vlc-wav-profile-encapsulation.png\" width=\"600\"/>\n",
    "<img src=\"resources/vlc-wav-profile-audio-codec.png\" width=\"600\"/>\n",
    "\n",
    "3. Save profile and click Convert!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip WAV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import wav_utils\n",
    "importlib.reload(wav_utils)\n",
    "from wav_utils import load_wav_file, clip_wav_arr, convert_frames_to_seconds, save_wave_arr, mix_wav_arrs\n",
    "\n",
    "input_wav_file_1 = \"downloaded/Cello Suite no. 3 in C, BWV 1009 - 3. Courante-converted.wav\"\n",
    "output_wav_file_1 = \"output/individual-clip-01.wav\"\n",
    "\n",
    "input_wav_file_2 = \"downloaded/The Carnival of the Animals - XIII. The Swan (Solo piano version)-converted.wav\"\n",
    "output_wav_file_2 = \"output/individual-clip-02.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load WAV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded/Cello Suite no. 3 in C, BWV 1009 - 3. Courante-converted.wav\n",
      "\tframe_rate:     44100\n",
      "\tnum_frames:     5288879\n",
      "\tlength_seconds: 119.9\n",
      "downloaded/The Carnival of the Animals - XIII. The Swan (Solo piano version)-converted.wav\n",
      "\tframe_rate:     44100\n",
      "\tnum_frames:     8796212\n",
      "\tlength_seconds: 199.5\n"
     ]
    }
   ],
   "source": [
    "signal_1, frame_rate_1 = load_wav_file(input_wav_file_1)\n",
    "signal_2, frame_rate_2 = load_wav_file(input_wav_file_2)\n",
    "\n",
    "print(f\"{input_wav_file_1}\")\n",
    "print(f\"\\tframe_rate:     {frame_rate_1}\")\n",
    "print(f\"\\tnum_frames:     {len(signal_1)}\")\n",
    "print(f\"\\tlength_seconds: {convert_frames_to_seconds(len(signal_1)):.1f}\")\n",
    "\n",
    "print(f\"{input_wav_file_2}\")\n",
    "print(f\"\\tframe_rate:     {frame_rate_2}\")\n",
    "print(f\"\\tnum_frames:     {len(signal_2)}\")\n",
    "print(f\"\\tlength_seconds: {convert_frames_to_seconds(len(signal_2)):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 20 second clips to mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/individual-clip-01.wav\n",
      "output/individual-clip-02.wav\n"
     ]
    }
   ],
   "source": [
    "# NOTE: the second wav file is very quiet the first 7 seconds, so start clip later\n",
    "clipped_signal_1 = clip_wav_arr(signal_1, start=0, end=20, unit=\"second\")\n",
    "clipped_signal_2 = clip_wav_arr(signal_2, start=7, end=27, unit=\"second\")\n",
    "\n",
    "# write them to file\n",
    "print(output_wav_file_1)\n",
    "save_wave_arr(clipped_signal_1, output_wav_file_1)\n",
    "\n",
    "print(output_wav_file_2)\n",
    "save_wave_arr(clipped_signal_2, output_wav_file_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mixed WAV files\n",
    "\n",
    "The goal is to simulate having two microphones in a room where both the cello and piano music is being played.\n",
    "\n",
    "- **Mix 1**: mimic cello music being closer and thus a little louder\n",
    "- **Mix 2**: mimic piano music being closer and thus a little louder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/mix-clip-01.wav\n",
      "output/mix-clip-02.wav\n"
     ]
    }
   ],
   "source": [
    "indiv_input_file_1 = \"output/individual-clip-01.wav\" # cello\n",
    "indiv_input_file_2 = \"output/individual-clip-02.wav\" # piano\n",
    "mix_output_file_1 = \"output/mix-clip-01.wav\" # cello louder than piano\n",
    "mix_output_file_2 = \"output/mix-clip-02.wav\" # piano louder than cello\n",
    "frac_volume = 0.7 # fraction of volume in mix allocated to the \"primary\" music\n",
    "\n",
    "# load input files\n",
    "signal_1, frame_rate_1 = load_wav_file(indiv_input_file_1)\n",
    "signal_2, frame_rate_2 = load_wav_file(indiv_input_file_2)\n",
    "\n",
    "# create the mixes\n",
    "mix_1 = mix_wav_arrs([signal_1, signal_2], [frac_volume, 1.0 - frac_volume])\n",
    "mix_2 = mix_wav_arrs([signal_1, signal_2], [1.0 - frac_volume, frac_volume])\n",
    "\n",
    "# save mixes to file\n",
    "print(mix_output_file_1)\n",
    "save_wave_arr(mix_1, mix_output_file_1)\n",
    "\n",
    "print(mix_output_file_2)\n",
    "save_wave_arr(mix_2, mix_output_file_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity-pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
